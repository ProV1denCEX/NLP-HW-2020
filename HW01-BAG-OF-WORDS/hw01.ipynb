{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T18:06:03.987080Z",
     "start_time": "2020-02-23T18:06:03.889691Z"
    }
   },
   "source": [
    "<h1><center>HW1 Movie Review Sentiment Analysis</center></h1>\n",
    "<h2><center>Due: March 2020 6th, 23:59</center></h2>\n",
    "\n",
    "In this homework you will create different models to generate the positive/negative sentiment\n",
    "classification of movie reviews.\n",
    "\n",
    "This homework should be done individually without cooperation with others.\n",
    "\n",
    "You are given the following files:\n",
    "- `hw01.ipynb`: Notebook file with starter code\n",
    "- `train.txt`: Training set to train your model\n",
    "- `test.txt`: Test set to report your model’s performance\n",
    "- `sample_prediction.csv`: Sample file your prediction result should look like\n",
    "- `utils/`: folder containing all utility code for the series of homeworks\n",
    "\n",
    "Remember to leverage code in `utils/`, so you don't have to build everything from\n",
    "Scratch.\n",
    "- `load_data(filename)`: load the input data and return sklearn.Bunch object. For basic\n",
    "usage of Bunch object, please refer to sklearn documentation.\n",
    "- `save_prediction(arr, filename)`: save your prediction into the format required by the\n",
    "course\n",
    "\n",
    "<h3> 0. Install Anaconda </h3>\n",
    "\n",
    "If you do not yet have Python and Jupyter Notebook on your laptop, use this link\n",
    "(https://www.anaconda.com/) to install anaconda. Anaconda is a suite that provides one\n",
    "stop solution for all you need for Python development environment. This site contains\n",
    "installation document for Windows, Mac, and Linux, choose the one that suits your operating\n",
    "system.\n",
    "\n",
    "*Tips: You may want to consider installing Jupyter Extensions (link: https://github.com/ipython-contrib/jupyter_contrib_nbextensions), and turn on extensions such as `ExcuteTime` and \n",
    "`Table of Contents(2)`. You may find them very helpful to assist you finishing homework. However, this \n",
    "is definitely not a necessary requirement.*\n",
    "\n",
    "<h3> 1. Feature Dictionary Vectorization </h3> \n",
    "\n",
    "A quite unique step for NLP is to engineer the raw text input into numerical features. You will\n",
    "eventually implement several featurizers, just like `dummy_featurize`, that distinguish your\n",
    "models with others. However, we are not there yet. For convenience we allow you to\n",
    "represent the features using a dictionary, look at the `dummy_featurize` code. So each data\n",
    "point can be translated into a dictionary. However later we have to translate this list of\n",
    "dictionaries into a homogeneous data structure. Therefore, you need to first implement the\n",
    "pipeline method in the `SentimetnClassifier` class. Look into the code comment for more\n",
    "details. To ensure your implementation works, we also provided some test code in the cell\n",
    "below.\n",
    "\n",
    "<h3> 2. Better featurizers </h3>\n",
    "\n",
    "Have you finished the first step, you can run the model using the provided featurizer. See\n",
    "the performance is nearly as good as a donkey? No surprise! The `dummy_featurize` should\n",
    "have been named `really_dummy_featurize`. Now it is your turn to implement better\n",
    "featurizers. For this homework, you need to implement at least 3 distinguishable featurizer.\n",
    "Describe your features briefly in the write-up and include the accuracy of the model. No idea\n",
    "at all? Look at your lecture notes for inspiration. Still no clue? Why not start with Bag of\n",
    "words?\n",
    "\n",
    "*Note: Model performance is important but it’s not the only thing we care about, your work will\n",
    "also be rewarded by your creativity.*\n",
    "\n",
    "<h3> 3. Optional: Try different learning methods </h3> \n",
    "\n",
    "All the work you have done so far are related to feature engineering, and the featurized data\n",
    "is trained using Logistic Regression. Try to use different learning methods to train the model\n",
    "and see if you achieve any difference in the performance. Discuss your findings in the\n",
    "write-up.\n",
    "\n",
    "<h3> 4. Deliverables (zip them all) </h3>\n",
    "\n",
    "- pdf version of your final notebook\n",
    "- Use the best model you trained, generate the prediction for test.txt, name the\n",
    "output file prediction.csv (Be careful: the best model in your training set might not\n",
    "be the best model for the test set).\n",
    "- HW1_writeup.pdf: summarize the method you used and report their performance.\n",
    "If you worked on the optional task, add the discussion. Add a short essay\n",
    "discussing the biggest challenges you encounter during this assignment and\n",
    "what you have learnt.\n",
    "\n",
    "(**You are encouraged to add the writeup doc into your notebook\n",
    "using markdown/html langauge, just like how this notes is prepared**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============== Coding Starts Here ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:52:00.680659Z",
     "start_time": "2020-02-23T20:51:58.055407Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# add utils folder to path\n",
    "p = os.path.dirname(os.getcwd())\n",
    "if p not in sys.path:\n",
    "    sys.path = [p] + sys.path\n",
    "    \n",
    "from utils.hw1 import load_data, save_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:55:11.104653Z",
     "start_time": "2020-02-23T20:55:11.051932Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!! Do not modify !!\n",
    "\"\"\"\n",
    "def dumb_featurize(text):\n",
    "    feats = {}\n",
    "    words = text.split(\" \")\n",
    "\n",
    "    for word in words:\n",
    "        if word == \"love\" or word == \"like\" or word == \"best\":\n",
    "            feats[\"contains_positive_word\"] = 1\n",
    "        if word == \"hate\" or word == \"dislike\" or word == \"worst\" or word == \"awful\":\n",
    "            feats[\"contains_negative_word\"] = 1\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:55:12.640127Z",
     "start_time": "2020-02-23T20:55:12.587171Z"
    }
   },
   "outputs": [],
   "source": [
    "def better_featurize(text):\n",
    "    raise NotImplementedError\n",
    "    \"\"\"\n",
    "    !! Do not work on this yet, work on the model and come back later !!\n",
    "    \n",
    "    Write your own code below\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:55:14.685120Z",
     "start_time": "2020-02-23T20:55:14.618559Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class SentimentClassifier:\n",
    "    def __init__(self, feature_method=dumb_featurize, min_feature_ct=1, L2_reg=1.0):\n",
    "        \"\"\"\n",
    "        :param feature_method: featurize function\n",
    "        :param min_feature_count: int, ignore the features that appear less than this number to avoid overfitting\n",
    "        \"\"\"\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.min_feature_ct = min_feature_ct\n",
    "        self.L2_reg = L2_reg\n",
    "\n",
    "    def featurize(self, X):\n",
    "        \"\"\"\n",
    "        # Featurize input text\n",
    "\n",
    "        :param X: list of texts\n",
    "        :return: list of featurized vectors\n",
    "        \"\"\"\n",
    "        featurized_data = []\n",
    "        for text in X:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    def pipeline(self, X, training=False):\n",
    "        \"\"\"\n",
    "        Data processing pipeline to translate raw data input into sparse vectors\n",
    "        :param X: featurized input\n",
    "        :return X2: 2d sparse vectors\n",
    "        \n",
    "        Implement the pipeline method that translate the dictionary like feature vectors into \n",
    "        homogeneous numerical vectors, for example:\n",
    "        [{\"fea1\": 1, \"fea2\": 2}, \n",
    "         {\"fea2\": 2, \"fea3\": 3}] \n",
    "         --> \n",
    "         [[1, 2, 0], \n",
    "          [0, 2, 3]]\n",
    "          \n",
    "        Hints:\n",
    "        1. How can you know the length of the feature vector?\n",
    "        2. When should you use sparse matrix?\n",
    "        3. Have you treated non-seen features properly?\n",
    "        4. Should you treat training and testing data differently?\n",
    "        \"\"\"\n",
    "        # Have to build feature_vocab during training\n",
    "        if training:\n",
    "            raise NotImplementedError\n",
    "         \n",
    "        # Translate raw texts into vectors\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return X2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.pipeline(self.featurize(X), training=True)\n",
    "\n",
    "        D, F = X.shape\n",
    "        self.model = LogisticRegression(C=self.L2_reg)\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.pipeline(self.featurize(X))\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        X = self.pipeline(self.featurize(X))\n",
    "        return self.model.score(X, y)\n",
    "\n",
    "    # Write learned parameters to file\n",
    "    def save_weights(self, filename='weights.csv'):\n",
    "        weights = [[\"__intercept__\", self.model.intercept_[0]]]\n",
    "        for feat, idx in self.feature_vocab.items():\n",
    "            weights.append([feat, self.model.coef_[0][idx]])\n",
    "        \n",
    "        weights = pd.DataFrame(weights)\n",
    "        weights.to_csv(filename, header=False, index=False)\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T19:58:51.448435Z",
     "start_time": "2020-02-23T19:58:51.341871Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this to test your model implementation\n",
    "\"\"\"\n",
    "\n",
    "cls = SentimentClassifier()\n",
    "X_train = [{\"fea1\": 1, \"fea2\": 2}, {\"fea2\": 2, \"fea3\": 3}]\n",
    "\n",
    "X = cls.pipeline(X_train, True)\n",
    "assert X.shape[0] == 2 and X.shape[1] >= 3, \"Fail to vectorize training features\"\n",
    "\n",
    "X_test = [{\"fea1\": 1, \"fea2\": 2}, {\"fea2\": 2, \"fea3\": 3}]\n",
    "X = cls.pipeline(X_test)\n",
    "assert X.shape[0] == 2 and X.shape[1] >= 3, \"Fail to vectorize testing features\"\n",
    "\n",
    "X_test = [{\"fea1\": 1, \"fea2\": 2}, {\"fea2\": 2, \"fea4\": 3}]\n",
    "try:\n",
    "    X = cls.pipeline(X_test)\n",
    "    assert X.shape[0] == 2 and X.shape[1] >= 3\n",
    "except:\n",
    "    raise Exception(\"Fail to treat un-seen features\")\n",
    "    \n",
    "print(\"Success!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:55:17.432616Z",
     "start_time": "2020-02-23T20:55:17.086834Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell to test your model\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_data(\"train.txt\")\n",
    "X, y = data.text, data.target\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.3)\n",
    "cls = SentimentClassifier(feature_method=dumb_featurize)\n",
    "cls = cls.fit(X_train, y_train)\n",
    "print(\"Training set accuracy: \", cls.score(X_train, y_train))\n",
    "print(\"Dev set accuracy: \", cls.score(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T19:59:41.183712Z",
     "start_time": "2020-02-23T19:59:40.752925Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell to save weights and the prediction\n",
    "\"\"\"\n",
    "weights = cls.save_weights()\n",
    "\n",
    "X_test = load_data(\"test.txt\").text\n",
    "save_prediction(cls.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Example of better featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T20:00:38.032607Z",
     "start_time": "2020-02-23T20:00:00.458431Z"
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    word_bag = Counter(text.lower().split(\" \"))\n",
    "\n",
    "    # do stuff here\n",
    "\n",
    "    return word_bag\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_data(\"train.txt\")\n",
    "X, y = data.text, data.target\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.3)\n",
    "cls = SentimentClassifier(feature_method=bag_of_words, min_feature_ct=10)\n",
    "cls = cls.fit(X_train, y_train)\n",
    "print(\"Training set accuracy: \", cls.score(X_train, y_train))\n",
    "print(\"Dev set accuracy: \", cls.score(X_dev, y_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
